from pyspark.sql import SparkSession
from pyspark.sql.functions import substring, expr, concat_ws, col, when, lpad, length, round, trim, first, to_date, isnan,lower, regexp_replace, row_number
from pyspark.sql import Window

# Initialiser Spark
spark = SparkSession.builder.appName("CleanCegidSales").getOrCreate()

# Charger les donn√©es JSON avec mode multiligne
print("\nüì• Chargement du fichier JSON...")
df = spark.read.option("multiline", "true").json("data/cegid/2024_cegid_sales.json")


# V√©rifier si le fichier est bien charg√©
print("\nüìä Structure des donn√©es :")
df.printSchema()

# V√©rifier les 5 premi√®res lignes
print("\nüîç Aper√ßu des donn√©es brutes :")
df.show(5, truncate=False)

# V√©rifier les doublons
print("\nüîç V√©rification des doublons AVANT transformation :")
df.groupBy("sale_id").count().filter(col("count") > 1).show(20, truncate=False)


# V√©rifier si des erreurs de chargement existent (_corrupt_record)
if "_corrupt_record" in df.columns:
    print("\n‚ö†Ô∏è ATTENTION : Des lignes corrompues ont √©t√© d√©tect√©es !")
    df.select("_corrupt_record").show(10, truncate=False)

# Charger en brut pour voir le contenu
df_raw = spark.read.text("data/cegid/2024_cegid_sales.json")
print("\nüìú Aper√ßu du fichier brut (premi√®res lignes) :")
df_raw.show(10, truncate=False)

# V√©rifier le nombre de lignes avant transformation
print(f"\nüìè Nombre total de lignes avant transformation : {df.count()}")


#############################################################################################
######################### Modification mail #################################################
#############################################################################################

# üè∑Ô∏è Remplacer les emails vides ou NULL par "non_renseign√©"
#df = df.withColumn("email",
#    when(col("email").isNull(), "non_renseign√©e")  # NULL ‚Üí "non_renseign√©"
#    .when(trim(col("email")) == "", "non_renseign√©e")  # " " (vide) ‚Üí "non_renseign√©"
#    .otherwise(col("email"))  # Sinon, on garde l'email existant
#)
# üè∑Ô∏è Nettoyer la colonne email
df = df.withColumn("email",
    trim(lower(col("email")))  # Convertir en minuscule et supprimer les espaces autour
)
# ‚úÖ V√©rification apr√®s transformation
print("\n‚úÖ V√©rification de la colonne email :")
df.select("email").show(10, truncate=False)


#############################################################################################
######################### Modification DATE #################################################
#############################################################################################

# üè∑Ô∏è Convertir transaction_date en format date
df = df.withColumn("transaction_date_clean", to_date(col("transaction_date"), "yyyy-MM-dd"))

# üîç V√©rifier les dates mal format√©es
df_invalid_dates = df.filter(col("transaction_date_clean").isNull() & col("transaction_date").isNotNull())

print("\n‚ö†Ô∏è Anomalies d√©tect√©es dans transaction_date :")
df_invalid_dates.select("transaction_date").show(20, truncate=False)

# üîç V√©rifier les dates dans le futur (ex: apr√®s aujourd‚Äôhui)
from pyspark.sql.functions import current_date

df_future_dates = df.filter(col("transaction_date_clean") > current_date())

print("\n‚ö†Ô∏è Dates futures suspectes :")
df_future_dates.select("transaction_date").show(20, truncate=False)


#############################################################################################
######################### Modification sale_id ##############################################
#############################################################################################


# Extraire les 4 premiers caract√®res (store_id) et l'ann√©e/mois de sale_id
df = df.withColumn("store_id_from_sale", substring(col("sale_id"), 1, 4))
df = df.withColumn("year_month_from_sale", substring(col("sale_id"), 5, 4))

# V√©rifier apr√®s extraction
print("\n‚úÖ V√©rification apr√®s extraction des IDs :")
df.select("sale_id", "store_id_from_sale", "year_month_from_sale").show(5, truncate=False)

# Extraire l'ann√©e et le mois corrects √† partir de transaction_date
df = df.withColumn("year_month_from_date", expr("date_format(transaction_date, 'yyyyMM')"))



# üéØ Transformer le format YYYYMM en YYMM
df = df.withColumn("year_month_yy", expr("substring(year_month_from_date, 3, 4)"))  # Prend YYMM


# ‚úÖ V√©rification apr√®s extraction de l'ann√©e/mois
print("\n‚úÖ V√©rification apr√®s extraction de year_month_from_date :")
df.select("transaction_date", "year_month_from_date", "year_month_yy").show(5, truncate=False)


# Correction du sale_id si store_id incorrect ou ann√©e/mois incorrects
store_ids = ["PA01", "PA02", "PA03", "BO01", "BO02", "MO01", "LY01", "LY02", "MA01", "LI01", "RE01", "ST01", "CL01"]



# üè™ Correction FORC√âE des store_id mal form√©s
df = df.withColumn("store_id_from_sale", substring(col("sale_id"), 1, 4))  # Prendre toujours les 4 premiers caract√®res

df = df.withColumn("store_id",
    when(col("store_id_from_sale").isin(store_ids), col("store_id_from_sale"))  # Si d√©j√† correct, on garde
    .when(col("store_id_from_sale").startswith("XXMO"), "MO01")
    .when(col("store_id_from_sale").startswith("XXCL"), "CL01")
    .when(col("store_id_from_sale").startswith("XXLI"), "LI01")
    .when(col("store_id_from_sale").startswith("XXRE"), "RE01")
    .when(col("store_id_from_sale").startswith("XXST"), "ST01")
    .when(col("store_id_from_sale").startswith("XXPA"), "PA01")  # PA02 et PA03 ‚Üí PA01
    .when(col("store_id_from_sale").startswith("XXBO"), "BO01")  # BO02 ‚Üí BO01
    .when(col("store_id_from_sale").startswith("XXLY"), "LY01")  # LY02 ‚Üí LY01
    .otherwise("UNKNOWN")  # Si encore inconnu, on met "UNKNOWN"
)


# ‚úÖ V√©rification apr√®s correction des store_id
print("\n‚úÖ V√©rification apr√®s correction FORC√âE des store_id :")
df.select("sale_id", "store_id_from_sale", "store_id").show(10, truncate=False)

print("\nüîç V√©rification des lignes en double sur sale_id AVANT transformation :")
df.filter(col("sale_id").isin(["MO01240100002", "BO02240800001", "MO01240800001"])).show(truncate=False)


print("\nüîç V√©rification des valeurs qui vont √™tre modifi√©es :")
df.filter((~col("store_id_from_sale").isin(store_ids)) |
          (col("year_month_from_sale") != col("year_month_yy"))
         ).select("sale_id", "store_id_from_sale", "year_month_from_sale", "year_month_yy").show(20, truncate=False)


# üè∑Ô∏è Ne modifier `sale_id` QUE si le `store_id` ou `year_month` est incorrect
df = df.withColumn("sale_id",
    when(
        (~col("store_id_from_sale").isin(store_ids)) |  # Si `store_id` invalide
        ((col("year_month_from_sale") != col("year_month_yy")) & col("year_month_from_sale").isNotNull()),  # V√©rification stricte sur l'ann√©e/mois
        concat_ws("", col("store_id"), col("year_month_yy"), substring(col("sale_id"), 9, 5))
    ).otherwise(col("sale_id"))
)

# ‚úÖ V√©rification apr√®s correction finale du sale_id
print("\n‚úÖ V√©rification apr√®s correction finale du sale_id :")
df.select("sale_id", "store_id_from_sale", "store_id", "year_month_yy").show(10, truncate=False)

print("\n‚úÖ V√©rification des doublons APR√àS transformation :")
df.groupBy("sale_id").count().filter(col("count") > 1).show(20, truncate=False)

#############################################################################################
######################### Correction des doublons de sales_id ################################
#############################################################################################

# Cr√©er une fen√™tre pour num√©roter les doublons
window_spec = Window.partitionBy("sale_id").orderBy("transaction_date")
df = df.withColumn("row_num", row_number().over(window_spec))

# Fonction pour incr√©menter le dernier num√©ro sans cr√©er de nouveaux doublons
def increment_last_number(df):
    # Identifier les sales_id existants pour √©viter de cr√©er de nouveaux doublons
    existing_sales_ids = set(row.sale_id for row in df.select("sale_id").distinct().collect())

    processed_df = df
    for sale_id in df.filter(col("row_num") > 1).select("sale_id").distinct().collect():
        base_id = sale_id.sale_id[:-2]  # Prendre tout sauf les 2 derniers chiffres

        # Trouver le prochain num√©ro disponible
        i = 1
        while base_id + str(i).zfill(2) in existing_sales_ids:
            i += 1

        # Mettre √† jour le sale_id
        processed_df = processed_df.withColumn(
            "sale_id",
            when(
                (col("sale_id") == sale_id.sale_id) & (col("row_num") > 1),
                expr(f"'{base_id}' || lpad('{i}', 2, '0')")
            ).otherwise(col("sale_id"))
        )

        # Ajouter le nouveau sale_id √† l'ensemble des existants
        existing_sales_ids.add(base_id + str(i).zfill(2))

    return processed_df

# Appliquer l'incr√©mentation
df = increment_last_number(df)

# Supprimer la colonne temporaire
df = df.drop("row_num")

# V√©rifier qu'il n'y a plus de doublons
print("\n‚úÖ V√©rification finale des doublons apr√®s correction :")
df.groupBy("sale_id").count().filter(col("count") > 1).show()

#############################################################################################
######################### Modification type colonne #########################################
#############################################################################################


# üè∑Ô∏è Supprimer les colonnes temporaires
df = df.drop("store_id_from_sale", "year_month_from_sale", "year_month_from_date", "store_id")
print("\n‚úÖ V√©rification apr√®s suppression des colonnes temporaires :")
df.show(5, truncate=False)

# V√©rifier le nombre total de lignes apr√®s transformation
print(f"\nüìè Nombre total de lignes apr√®s transformation : {df.count()}")


# V√©rifier les sale_id avec une longueur diff√©rente de 13
df.filter(length(col("sale_id")) != 13).select("sale_id").show(20, truncate=False)

# Compter combien de sale_id ont une longueur incorrecte
count_incorrect = df.filter(length(col("sale_id")) != 13).count()
print(f"\nüìè Nombre total de sale_id incorrects (‚â† 13 caract√®res) : {count_incorrect}")

#############################################################################################
######################### Modification price ################################################
#############################################################################################

# üè∑Ô∏è Calculer `price_unitaire` correct pour chaque `product_name` en excluant les valeurs invalides
df_price_lookup = df.filter(
    (col("price").isNotNull()) & (~isnan(col("price"))) & (trim(col("price")) != "") & (col("price") != "X") & (col("price").cast("double").isNotNull())
).withColumn("price_unitaire", (col("price") / col("quantity")).cast("double"))

# üè∑Ô∏è Agr√©ger le premier `price_unitaire` valide pour chaque `product_name`
df_price_lookup = df_price_lookup.groupBy("product_name").agg(first("price_unitaire", ignorenulls=True).alias("ref_price_unitaire"))

# üè∑Ô∏è Joindre ce `price_unitaire` de r√©f√©rence sur le DataFrame principal
df = df.join(df_price_lookup, on="product_name", how="left")

# üè∑Ô∏è Remplacer les valeurs invalides de `price` par `ref_price_unitaire * quantity`
df = df.withColumn("price",
    when(
        (col("price").isNull()) | (trim(col("price")) == "") | (col("price") == "X") | (col("price").cast("double").isNull()),
        round(col("ref_price_unitaire") * col("quantity"), 2)  # Remplacement par `price_unitaire * quantity`
    )
    .otherwise(col("price").cast("double"))  # Sinon, garder la valeur existante
)

# üè∑Ô∏è Supprimer la colonne temporaire `ref_price_unitaire`
df = df.drop("ref_price_unitaire")

# ‚úÖ V√©rification apr√®s transformation
print("\n‚úÖ V√©rification de la colonne price apr√®s correction des valeurs invalides :")
df.select("product_name", "quantity", "price").show(10, truncate=False)


#############################################################################################
######################### Modification type colonne #########################################
#############################################################################################

# üè∑Ô∏è Convertir les types des colonnes
df = df.withColumn("price", col("price").cast("double"))  # Garde price en float
df = df.withColumn("quantity", col("quantity").cast("int"))  # Convertir en int (moins de m√©moire)
df = df.withColumn("transaction_date", to_date(col("transaction_date"), "yyyy-MM-dd"))  # Date propre
df = df.withColumn("year_month_yy", col("year_month_yy").cast("string"))  # Garde en string
df = df.withColumn("sale_id", col("sale_id").cast("string"))  # Garde en string
df = df.withColumn("email", col("email").cast("string"))  # Garde en string
df = df.withColumn("product_name", col("product_name").cast("string"))  # Garde en string

# ‚úÖ V√©rification apr√®s transformation
print("\n‚úÖ V√©rification finale du sch√©ma des colonnes :")
df.printSchema()


# üè∑Ô∏è Remplacer l'ancienne colonne transaction_date par la version propre
df = df.drop("transaction_date").withColumnRenamed("transaction_date_clean", "transaction_date")

# ‚úÖ V√©rification apr√®s remplacement
print("\n‚úÖ V√©rification finale de transaction_date :")
df.select("transaction_date").show(10, truncate=False)

# üè∑Ô∏è V√©rifier le sch√©ma final
df.printSchema()

# üè∑Ô∏è Supprimer la colonne year_month_yy √† la fin
df = df.drop("year_month_yy")

# ‚úÖ V√©rification apr√®s suppression
print("\n‚úÖ V√©rification du sch√©ma apr√®s suppression de year_month_yy :")
df.printSchema()



#############################################################################################
######################### Export CSV propre #################################################
#############################################################################################

df.write.mode("overwrite").csv("data/cegid/cleaned_cegid_sales.csv", header=True)


